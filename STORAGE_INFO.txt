================================================================================
                    WEATHER DATA STORAGE INFORMATION
================================================================================

CURRENT STORAGE STATUS:
-----------------------
âœ“ Currently using: LOCAL FILESYSTEM (HDFS is not available)

Storage Location:
  C:\Users\miana\OneDrive\Desktop\Uni works\big data project\BDA-Lab-Project\data

Data Structure (mirrors HDFS structure):
  data/
    apps/
      weather/
        ingest/
          date=YYYY-MM-DD/
            city.jsonl

Example:
  data/apps/weather/ingest/date=2025-11-11/lahore.jsonl
  data/apps/weather/ingest/date=2025-11-11/islamabad.jsonl

Total Files: 38 weather data files stored


HOW STORAGE WORKS:
------------------
1. The system FIRST tries to connect to HDFS (Hadoop Distributed File System)
2. If HDFS is unavailable, it AUTOMATICALLY falls back to local storage
3. The local storage structure matches HDFS structure exactly
4. This allows seamless switching between HDFS and local storage


TO USE HADOOP HDFS INSTEAD:
---------------------------

Step 1: Install and Setup Hadoop
---------------------------------
You need to install Hadoop on your system. Here are the official resources:

Official Hadoop Website:
  https://hadoop.apache.org/

Hadoop Documentation:
  https://hadoop.apache.org/docs/current/

Hadoop Installation Guide:
  https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html

Hadoop on Windows:
  https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html#Windows

Alternative: Use Docker for Hadoop (Easier for Windows):
  https://github.com/big-data-europe/docker-hadoop


Step 2: Start Hadoop Services
------------------------------
After installing Hadoop, you need to start:
- NameNode (default port: 9870 for WebHDFS)
- DataNode

Check if Hadoop is running:
  http://localhost:9870 (NameNode Web UI)


Step 3: Set Environment Variables
----------------------------------
Create a .env file in the backend folder or set these in PowerShell:

  $env:HDFS_NAMENODE="http://localhost:9870"
  $env:HDFS_USER="your_username"
  $env:HDFS_BASE_DIR="/apps/weather"

Or create a .env file:
  HDFS_NAMENODE=http://localhost:9870
  HDFS_USER=miana
  HDFS_BASE_DIR=/apps/weather


Step 4: Restart Backend
-----------------------
The backend will automatically detect HDFS and use it instead of local storage.


HADOOP WEB INTERFACES:
---------------------
Once Hadoop is running, you can access:

NameNode Web UI:
  http://localhost:9870

This shows:
- HDFS file system browser
- Cluster information
- Storage statistics


CURRENT DATA FILES:
------------------
Your weather data is stored in JSONL format (one JSON record per line):
- Each file contains weather records for a specific city and date
- Files are organized by date partitions (date=YYYY-MM-DD)
- Format: {"city": "lahore", "timestamp": "...", "tempC": 25.5, ...}


VIEWING YOUR DATA:
-----------------
You can view the data files directly:
- Navigate to: BDA-Lab-Project\data\apps\weather\ingest\
- Open any .jsonl file in a text editor
- Each line is a JSON weather record


NOTES:
------
- The system automatically falls back to local storage if HDFS is unavailable
- Local storage structure matches HDFS exactly
- You can migrate data from local to HDFS later if needed
- For a semester project, local storage is perfectly fine for demos

================================================================================

