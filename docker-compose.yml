# Weather Analytics Dashboard - Docker Compose
# Architecture: Hadoop (HDFS) + Backend (FastAPI) with automatic data processing

services:
  # Hadoop NameNode
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    hostname: namenode
    ports:
      - "9870:9870"   # NameNode Web UI
      - "9000:9000"   # NameNode RPC
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./data:/data  # Mount local data directory
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    networks:
      - bigdata-network

  # Hadoop DataNode
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    hostname: datanode
    ports:
      - "9864:9864"   # DataNode Web UI
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
      - ./data:/data  # Mount local data directory
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env
    networks:
      - bigdata-network

  # Backend Service - FastAPI (processes data on startup)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: weather-backend
    hostname: backend
    ports:
      - "5000:5000"   # Backend API
    volumes:
      - ./data:/app/data  # Mount data directory for reading/writing
    environment:
      - DATA_DIR=/app/data
      - HDFS_NAMENODE=http://namenode:9870
      - HDFS_USER=hadoop
      - HDFS_BASE_DIR=/apps/weather
    depends_on:
      - namenode
      - datanode
    networks:
      - bigdata-network

  # Frontend Service - React UI
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: weather-frontend
    hostname: frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - bigdata-network

volumes:
  hadoop_namenode:
  hadoop_datanode:

networks:
  bigdata-network:
    driver: bridge
